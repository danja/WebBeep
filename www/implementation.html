<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta http-equiv="content-type" content="text/html; charset=us-ascii">
  <title>Web Beep : text to tones and back again</title>
  <meta name="description" content="Web Beep : text to tones and back again">
  <meta name="author" content="Danny Ayers">
  <link rel="shortcut icon" href="/favicon.ico">
  <!-- M$ etc -->
  <link rel="apple-touch-icon" href="/apple-icon.png">
  <!-- iDespair -->
  <link rel="icon" type="image/png" href="/apple-icon.png">
  <!-- HTML5 -->
  <link rel="stylesheet" href="fonts/font.css" type="text/css" media="Screen">
  <link rel="stylesheet" href="css/tabs.css" type="text/css" media="screen">
  <link rel="stylesheet" href="css/stuff.css" type="text/css" media="Screen">
  <script type="text/javascript" src="js/curvycorners.js">
 </script>
  <script type="text/javascript">
<!-- Google Plus -->
  (function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/plusone.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
  })();</script>
</head>

<body id="tab1">

<div id="fb-root">
</div>
<script type="text/javascript">
(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_GB/all.js#xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>
<ul id="topnav">
  <li class="xtab1"><a href="/" title="Danny Ayers' Blog">Raw Blog</a> </li>
  <li class="xtab2"><a href="http://hyperdata.org/danja/"
    title="my updates on various social sites">Planet Danja</a> </li>
  <li class="xtab3"><a href="http://hyperdata.org/planet/"
    title="stuff I'm watching">Planet Raw</a> </li>
  <li class="xtab4"><a href="http://hyperdata.org/"
    title="Linked Data related material">hyperdata.org</a> </li>
  <li class="xtab5"><a href="http://hyperdata.org/wiki/"
    title="on my personal wiki">Stuff</a> </li>
  <li class="xtab6"><a href="http://hyperdata.org/xmlns/"
    title="various namespaces/ontologies">Vocabs</a> </li>
  <li class="xtab7"><a href="http://dannyayers.com/about.html"
    title="About">About</a> </li>
</ul>
<br>


<div id="header">
<h1 id="page-title"><a href="index.html">Web Beep</a></h1>

<p id="description">how it works</p>
</div>

<div class="container">

<div class="sidebar-left">
<h3>Nearby</h3>
<ul>
  <li><a href="index.html">Home</a> </li>
  <li><a href="spec.html">Specification</a></li>
</ul>

<h3>Contents</h3>
<ul>
  <li><a href="#Design">Design</a></li>
  <li><a href="#Encoding">Encoding</a></li>
  <li><a href="#Decoding">Decoding</a></li>
  <li><a href="#Initial">Implementation</a></li>
  <li><a href="#Notes">Notes</a></li>
</ul>
</div>

<div class="container">

<div class="sidebar-right">
<h3><a name="Reference" id="Reference">Reference</a></h3>
<ul>
  <li><a href="http://en.wikipedia.org/wiki/Digital_audio">Digital Audio</a>
  </li>
  <li><a href="http://en.wikipedia.org/wiki/Digital_signal_processing">DSP</a>
  </li>
  <li><a href="http://en.wikipedia.org/wiki/Fft">FFT</a> </li>
  <li><a href="http://en.wikipedia.org/wiki/Goertzel_algorithm">Goertzel
    Algorithm</a> </li>
</ul>

<h3>Fanclub</h3>

<div class="nobullets">
<ul>
  <li>
    <div class="fb-like">
    </div>
  </li>
  <li><a href="https://twitter.com/share"
    class="twitter-share-button">Tweet</a> <script type="text/javascript">
!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="//platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
  </li>
  <li>&lt; g:plusone annotation="inline" width="140"
    href="http://webbeep.it"&gt;</                                        
    g:plusone></li>
</ul>
</div>

<h3>Elsewhere</h3>
<ul>
  <li><a href="http://dannyayers.com" title="Danny Ayers' Blog">Raw Blog</a>
  </li>
  <li><a href="http://hyperdata.org/"
    title="Linked Data related material">hyperdata.org</a> </li>
  <li><a href="http://dannyayers.com/stuff/" title="various things">Stuff</a>
  </li>
  <li><a href="http://spikeandwave.com" title="my music">Spike &amp; Wave</a>
  </li>
</ul>

<div class="nobullets">
<ul>
  <li><a href="http://twitter.com/danja"><img src="/images/twitter.png"
    alt="Twitter" width="24" height="24"></a></li>
  <li><a href="http://www.facebook.com/danny.ayers"><img src="/images/fb.png"
    alt="Facebook" width="24" height="24"></a></li>
  <li><a href="https://plus.google.com/112609322932428633493?rel=author"
    rel="author"><img src="/images/plus.png" alt="Google Plus" width="24"
    height="24"></a></li>
</ul>
</div>
</div>

<div class="content">

<blockquote>
  <p><strong>These sound exactly like computers did in 1950's SF movies !!!
  Finally the future is here ! </strong></p>
</blockquote>
- <cite><a href="https://plus.google.com/u/0/109176638585404116752">David
Lee</a></cite> 

<p></p>

<p></p>

<p></p>

<h1>Short Version</h1>

<p>The implementation was first written as a command-line application in Java.
The Web service is the same application with a simple embedded (Jetty) HTTP
server.</p>

<h2>Encode</h2>
<ul>
  <li>text input is converted into ASCII (Punycode with a checksum)</li>
  <li>each character is mapped to a high note, low note and duration (notes
    taken from a pentatonic scale)</li>
  <li>pure tones are generated and shaped according to the mapping</li>
</ul>

<p><img alt="Waveform of encoded &quot;abc&quot;" src="images/abc-wave.png"
width="800" height="200"></p>

<p><em>four pairs of tone bursts : checksum and the three characters</em></p>

<h2>Decode</h2>
<ul>
  <li>incoming tone is trimmed</li>
  <li>tone is split into chunks, each corresponding to one character</li>
  <li>each chunk is analysed to find tones present and durations</li>
  <li>tones mapped to ASCII characters</li>
  <li>text reassembled and converted back</li>
</ul>

<h1>Long Version : Introduction</h1>

<p>This write-up is rough &amp; ready, mostly I wanted notes for myself,
offboard memory. But however incoherent, hopefully it contains enough
information to explain how this thing works. </p>

<p>There is some digital signal processing jargon, but DSP can just be treated
as black-box stuff, there's really <strong>no need to go into the detailed
maths to build things</strong>. (It's been many years since I last worked on
stuff like this and my maths is totally rusted, the revision I did for this was
mostly skimming Wikipedia - see <a href="#Reference">Reference</a> links). </p>

<h1>Facets of Beep</h1>

<p>It took me about a month part-time to put the service together, but making
another implementation would take <em>much</em> less time. My early attempts
used a fairly suboptimal system configuration and most of the time was spent
trying to optimize it. Now a usable configuration has been arrived at, the
optimization overhead is no longer necessary. But space exploration can be
fun...</p>

<p></p>
<ul>
  <li><strong>Beeps and the Web</strong> : see <a
    href="http://wiki.foaf-project.org/w/DanBri/ChirpChirp">ChirpChirp</a>
    <em>[and <a href="#PS">PS below</a>] </em></li>
  <li><strong>DSP Optimization using a Genetic Algorithm</strong> : the first
    version of the system was sensitive to noise and distortion so I added some
    filters etc. for pre- and post-processing. There were a lot of parameters
    to tweak so I hooked up a genetic algorithm to optimize the thing
    automatically.</li>
  <li><strong>DSP Representation on the Web of Data</strong> : to be able to
    change configuration and parameters easily, a systematic representation was
    needed. I hacked up the current internal representation as I went along,
    but it's crying out to be done in a standard fashion. RDF is the obvious
    choice, so I've started a <a href="http://hyperdata.org/xmlns/dsp/">DSP
    vocabulary/ontology</a>. I know exactly how to proceed with this, see <a
    href="#Future">Future Directions</a>.</li>
</ul>

<h1><a id="Design">Design Considerations</a></h1>

<p>The original idea was to encode HTTP URLs as little tunes, with the
characters in URLs <em>somehow</em> mapping to musical notes. It's essentially
the same idea as used in <a
href="http://en.wikipedia.org/wiki/Touch_tone">touch-tone</a> phone signals,
but tweaked to make the beeps easier on the ear. </p>

<h2>Text Processing</h2>

<p>International coverage (i.e. <a
href="http://en.wikipedia.org/wiki/Internationalized_Resource_Identifier">IRI</a>s)
is fairly essential, which basically means supporting <strong><a
href="http://en.wikipedia.org/wiki/Unicode">Unicode</a></strong>. Because of
this it was decided not to include any optimisations or other special features
for URLs, and simply support <strong>arbitrary text</strong>. Unicode contains
a <em>lot</em> of characters, and mapping from these to musical pitches
directly is almost certainly unfeasible. However <a
href="http://en.wikipedia.org/wiki/Punycode">Punycode</a> is an encoding syntax
by which a string of Unicode characters can be transformed uniquely and
reversibly into a much smaller character set. Basically it's <strong>a mapping
to ASCII</strong>. Roughly speaking, characters that can be expressed in ASCII
are expressed that way, but multiple ASCII characters are used to represent
other individual Unicode characters. In general, the cost of reducing the size
of the character set is an increase in the resulting string length. </p>

<h2>Phonic Constraints</h2>

<p>To achieve a reasonable compromise between length of (beep) messages,
musicality and implementation complexity, it was decided that a <strong>maximum
of two concurrent tones</strong> (one bass, one treble) was probably most
suitable. By restricting these to a <strong><a
href="http://en.wikipedia.org/wiki/Pentatonic">pentatonic scale</a></strong>,
arbitrary combinations of notes could be used without major dissonance. Another
consideration was that generic hardware should be able to transmit and receive
the beeps, so a range of pitches was chosen that should be suitable for common
electroacoustic transducers, i.e. nothing too low or too high (approx.
250-1500Hz, which is around female speech range and a bit higher, or an
extended soprano singer). The restriction to the notes of the pentatonic scale
(i.e. 5 per octave) meant a little more space for data was desirable, so the
treble notes may appear as half- or whole-length.</p>

<p>This may give the impression a lot of planning went into this aspect : not
really, most decisions were made during experimentation, based on what sounded
about right.</p>

<h1><a id="Encoding">Encoding</a></h1>

<p>Generating Web Beeps is relatively straightforward, details of the
requirements can be found in the <a href="spec.html">specification</a>, there's
an example of how this may be implemented in Java in the <a
href="https://github.com/danja/WebBeep">source code</a>.</p>

<p>This is how it's done:</p>

<p></p>

<p><img alt="encoding" src="images/encoding.png" width="862" height="595"></p>

<h2>DSP Blocks</h2>

<p>To play around with processing the audio signals both as individual
character chunks and the combined signal, the following pipeline was set up:</p>

<p><img alt="encoder block diagram" src="images/encoder-block1.png" width="862"
height="177"></p>

<p><em>sorry messy diagram - will tidy later</em></p>

<p>This is the generalized form of the setup - in practice not really needed,
experimentation showed that <strong>virtually no pre- or post-processing was
required</strong>.</p>

<p>The Chars to Chunks block is the most interesting bit. Each chunk,
corresponding to a single ASCII character, has a high frequency and a low
frequency component (high and low bits of the char) of duration 1 or 2 units.
</p>

<p>Lookup tables are used to determine appropriate frequencies for the low tone
and high tone, then the corresponding sine waves are generated and summed.</p>

<h1><a id="Decoding">Decoding</a></h1>

<p>Getting the text back out from the beeps is rather more convoluted (<em>hee
hee</em>), though is based on standard digital signal processing (<a
href="http://en.wikipedia.org/wiki/Digital_signal_processing">DSP</a>)
techniques. </p>

<p>Again, a generalized pipeline was set up. Here pre- and post-processing was
more of a consideration.</p>

<p><img alt="decoder block diagram" src="images/decoder-block1.png" width="857"
height="165"></p>

<p><strong>Split</strong> is done simplify by locating the start of the tone
and then chopping it into equal-sized lengths correcponding to the duration of
individual tones.</p>

<p><strong>Chunks to Chars</strong> is the interesting bit here. The decoder
has to find what tone (if any) occurs in each half of the chunk. Some kind of a
pitch detector is needed.</p>

<h1><a id="Initial" name="Initial">Implementation</a></h1>

<p>The reference implementation has been written in Java. </p>

<p>Generating signals is pretty easy, but manipulating them can get hard. So I
assumed I'd need to use a piece of kit like Octave (very like Matlab, only open
source). But as I got into it, it turned out to be straightforward, given the
material available on the Web. </p>

<p>For an internal representation of signals I started with a
<code>List&lt;Double&gt;</code>, expecting to have to turn everything over to
arrays at some point for performance (arrays give me a headache, always
out-by-one). That point didn't arrive, although I've had to translate to/from
arrays here and there for interfacing with libs. <em>Long live
Collections!</em></p>

<h2>Visualization</h2>

<p>I started by playing with generated tones in Audacity, passing them to and
from code as .wav files. Very clunky - it quickly became obvious there was
something I needed above anything else: a simple way of visualizing signals.</p>

<p>Scales and offsets are always a pain, but it didn't take that long to get
something together that was usable: </p>

<p><img alt="test tone plot" src="images/correlation-tone-plot.png" width="800"
height="200"></p>

<p>Plotter.java - a little bit of Swing which takes a List&lt;Double&gt; and
jams it in the window.</p>

<h4>FFT Detection</h4>

<p>The decoder was first developed using FFT for pitch detection - a suitable
FFT class was easily found online (a direct port of a C version). A peak
detector (to identify the peaks in the power spectrum delivered by the FFT) was
also needed. After several unsatisfying experiments I found a public domain
peak detector. The FFT+peak detector setup basically worked but proved very
sensitive to noise and distortion. The code for this is still in the
repository, it's handy having FFT around for spectrum analysis.</p>

<h4>Pre- and Post-Processing</h4>

<p>Because of the robustness problem, I hooked up a series of processing blocks
at various points in the pipeline to help reduce harmonic distorion artifacts
and out-of-band noise. Basically filters plus simple envelope shapers and
normalizers.</p>

<h4>Cross-correlation Blind Alley</h4>

<p>So I tried a second approach, experimenting with cross-correlation. My
intuition said there <em>must</em> be some way of correlating individual
reference tone sine waves with the Beep signals. Rather than run through every
frequency, as in FFT, just pick the ones of interest, the ones known to have
been used in generating the signal. </p>

<h2>Parameters, Parameters, Parameters</h2>

<p>So with the FFT setup I had a bunch of different pipeline modules, each
needing two or three parameters. This was a problem, especially since at least
some of them would interact with each other.</p>

<p>So I got coding again :</p>
<ul>
  <li>refactored the code to allow a systematic way of passing parameters to
    each of the modules</li>
  <li>set up a simulation of a noisy line between encoder and decoder</li>
  <li>decided on a fitness measure based on accuracy, performance etc.</li>
  <li>set up a genetic algorithm to make lots of little simulations and breed
    them</li>
</ul>

<h3>Some Parameters</h3>

<p>This is the current setup. Note that many of the parameters have the value
<strong>.on = false</strong>. It turned out that given a better pitch detection
algorithm, most of these were redundant.</p>
<pre><code>
Codec : class org.hyperdata.beeps.DefaultEncoder        
   Empty Pipeline
   Encoder.pre
        Component : Encoder.pre.chunkEnv = class org.hyperdata.beeps.processors.EnvelopeShaper
                Encoder.pre.chunkEnv.on = false
                Encoder.pre.chunkEnv.attackProportion = 0.06
                Encoder.pre.chunkEnv.decayProportion = 0.13
        Component : Encoder.pre.chunkNorm = class org.hyperdata.beeps.processors.Normalise
                Encoder.pre.chunkNorm.on = false
        Empty Pipeline
class org.hyperdata.beeps.DefaultDecoderCodec : class org.hyperdata.beeps.DefaultDecoderDecoder.core
        Component : Decoder.core.cropper = class org.hyperdata.beeps.processors.Cropper
                Decoder.core.cropper.silenceThreshold = 0.39328963702325803
                Decoder.core.cropper.on = true
        Component : Decoder.core.normalise = class org.hyperdata.beeps.processors.Normalise
                Decoder.core.normalise.on = false
        Component : Decoder.core.chunker = class org.hyperdata.beeps.processors.Chunker
                Decoder.core.chunker.cropProportion = 0.6337724901356069
                Decoder.core.chunker.on = true
        Component : Decoder.core.pitchFinder = class org.hyperdata.beeps.pitchfinders.GoertzelPitchFinder
                Decoder.core.pitchFinder.gThreshold = 4194.939772585178
Decoder.pre
        Component : Decoder.pre.compressor = class org.hyperdata.beeps.processors.Compressor
                Decoder.pre.compressor.on = false
                Decoder.pre.compressor.windowLength = 464
                Decoder.pre.compressor.lowThreshold = 0.6343658962166174
                Decoder.pre.compressor.highThreshold = 0.760342929650305
        Component : Decoder.pre.HP_FIR = class org.hyperdata.beeps.processors.FIRProcessor
                Decoder.pre.HP_FIR.shape = HP
                Decoder.pre.HP_FIR.on = false
                Decoder.pre.HP_FIR.window = Hamming
                Decoder.pre.HP_FIR.cutoff = 100.94422117466493
                Decoder.pre.HP_FIR.npoints = 1228
        Component : Decoder.core.normalise = class org.hyperdata.beeps.processors.Normalise
                Decoder.core.normalise.on = false
        Component : Decoder.pre.LP_FIR1 = class org.hyperdata.beeps.processors.FIRProcessor
                Decoder.pre.LP_FIR1.shape = LP
                Decoder.pre.LP_FIR1.on = false
                Decoder.pre.LP_FIR1.window = Hanning
                Decoder.pre.LP_FIR1.cutoff = 10285.082818002804
                Decoder.pre.LP_FIR1.npoints = 3795
        Component : Decoder.core.normalise = class org.hyperdata.beeps.processors.Normalise
                Decoder.core.normalise.on = false
        Component : Decoder.pre.LP_FIR2 = class org.hyperdata.beeps.processors.FIRProcessor
                Decoder.pre.LP_FIR2.shape = LP
                Decoder.pre.LP_FIR2.on = false
                Decoder.pre.LP_FIR2.window = Hanning
                Decoder.pre.LP_FIR2.cutoff = 1125.173350363232
                Decoder.pre.LP_FIR2.npoints = 89
        Component : Decoder.core.normalise = class org.hyperdata.beeps.processors.Normalise
                Decoder.core.normalise.on = false
Decoder.post
        Component : Decoder.post.chunkNorm = class org.hyperdata.beeps.processors.Normalise
                Decoder.post.chunkNorm.on = false
        Component : Decoder.post.chunkEnv = class org.hyperdata.beeps.processors.EnvelopeShaper
                Decoder.post.chunkEnv.on = true
                Decoder.post.chunkEnv.attackProportion = 0.14
                Decoder.post.chunkEnv.decayProportion = 0.091</code></pre>

<p><strong>Goertzel to the Rescue</strong></p>

<p>After spending loads of time on the FFT then Danny's Own Correlation
versions, I remembered the close similarity between the encoding here and the
encoding of DTFM signals. How's that usually done? Turns out that there's an
algorithm that in effect does the kind of known-freq correlation thing I was
looking for. It goes by the name of Goertzel. What's more it's remarkable
simple - from Wikipedia:</p>
<pre><code>
s_prev = 0
s_prev2 = 0
normalized_frequency = target_frequency / sample_rate;
coeff = 2*cos(2*PI*normalized_frequency);
for each sample, x[n],
  s = x[n] + coeff*s_prev - s_prev2;
  s_prev2 = s_prev;
  s_prev = s;
end
power = s_prev2*s_prev2 + s_prev*s_prev - coeff*s_prev*s_prev2;</code></pre>

<p></p>

<p>In Web Beep, the frequencies known to have been used in the creation of
Beeps (in the Character Mapping tables) are passed to the Goertzel algorithm in
turn, to test each chunk in turn. </p>

<p>The values obtained are used for a reverse-lookup of the characters from the
frequency/duration combinations.</p>

<h1><a id="Notes" name="Notes">Notes</a><a name="Future" id="Future">/ Future
Directions</a></h1>

<h2></h2>

<p>An in-browser Javascript implementation seems like a good step.</p>

<h2>Applications for Web Beep</h2>

<p>Dunno really, but see <a
href="http://wiki.foaf-project.org/w/DanBri/ChirpChirp">ChirpChirp</a> <em>[and
<a href="#PS">PS below</a>]</em></p>

<p>As a kind of QR Code for the ear, Web Beeps should be useful in a lot of
places. <em>Suggestions please...</em></p>

<p>Ring Tone - use your email, Home Page or personal URI. </p>

<h2>Application for the DSP bits</h2>

<p>Take it from me, pluggable, modular, parameterized,
declaratively-configurable DSP systems should have plenty of applications.
Making such things Web-friendly would almost certainly be very advantageous. So
I've started a <a href="http://hyperdata.org/xmlns/dsp/">DSP
vocab/ontology</a>.</p>

<p>The Java representation contains the important structural information needed
for described DSP systems, so my plan is to add a variant on the
<code>toString()</code> method in the classes of the code
(<code>describe()</code>) to deliver RDF/Turtle and use a bit of reflection to
get the code to describe itself.</p>

<p>To enhance this a bit there's David Huyn's RDFizer Javadoc thingy, which I
plan to tweak to use HTTP URLs (rather than its current URNs).</p>

<p>Now if someone will please suggest applications for Web-friendly pluggable,
modular, parameterized, declaratively-configurable DSP systems...</p>

<h2>Patent Pending?</h2>

<p><strong>No. </strong><strong><a
href="http://en.swpat.org/wiki/Blocking_innovation_and_research">Software
patents hurt innovation</a>.</strong></p>

<p>In any case, I'm sure many variations of this have been done before, though
it's hard to find out what there is. Searches I've tried mostly led to
something related to mobile/cellphone ringtones (I wanted the name "Web Tone"
but it's already taken).</p>

<p>The basic idea is fairly trivial: what if you had something like DTFM tones
only not so hard on the ear? Given that, implementations are pretty obvious
given minimal background knowledge of character encoding, music and DSP. Simple
matter of guesswork, experimentation &amp; banging out the code. The
implementation described here is pretty arbitrary, mostly based on what seemed
like a good idea at the time.</p>

<p><a href="https://github.com/danja/WebBeep">Please clone the project.</a></p>

<p></p>

<p><a name="PS" id="PS">PS</a>. I already held <a
href="http://danbri.org/">Danbri</a> responsible for the idea as he'd been
talking about something vaguely similar recently. What I'd completely forgotten
was that he'd suggested exactly this idea - and even done a write-up: <a
href="http://wiki.foaf-project.org/w/DanBri/ChirpChirp">ChirpChirp</a>. </p>

<p>OMG, I have become Danbri's personal LazyWeb...</p>

<p></p>

<div id="footer">
<p>(c) <a href="http://dannyayers.com">Danny Ayers</a> </p>

<p>This work is licensed for reuse <br>
<a rel="license" href="http://creativecommons.org/licenses/by/3.0/">Creative
Commons</a> <a rel="license"
href="http://creativecommons.org/licenses/by/3.0/"><br>
<img alt="Creative Commons License" style="border-width:0"
src="http://i.creativecommons.org/l/by/3.0/88x31.png"></a><br>
</p>
</div>
</div>
</div>
</div>
</body>
</html>
